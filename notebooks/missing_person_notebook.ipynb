{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable assignment and printing\n",
    "a = 5\n",
    "b = 3\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lists and for loops\n",
    "list_of_colors = [\"Violet\", \"Blue\", \"Green\", \"Yellow\", \"Orange\", \"Red\"]\n",
    "for color in list_of_colors:\n",
    "    #tab indicates that you are inside the loop\n",
    "    message = \"This is an item in the list: \" + color\n",
    "    print(message)\n",
    "#un-tab indicates that you are done with the for loop\n",
    "print(\"There are no more items in the list\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionaries: key-value pairs\n",
    "student_ages = {\"Jack\":15, \"Sarah\":17, \"Greg\": 12, \"Jamie\":14, \"Lucy\": 12}\n",
    "jamies_age = student_ages[\"Jamie\"]\n",
    "print(jamies_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"../data/merged_data_year_0.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"(n rows, n features):\")\n",
    "print(df0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One thousand features so let's look at a few\n",
    "var =  df0.iloc[:,100]\n",
    "print(var.name)\n",
    "print(var.head())\n",
    "var.value_counts().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "var =  df0.iloc[:,200]\n",
    "print(var.name)\n",
    "print(var.head())\n",
    "var.value_counts().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "var =  df0.iloc[:,300]\n",
    "print(var.name)\n",
    "print(var.head())\n",
    "var.value_counts().plot(kind=\"bar\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice?\n",
    "    \n",
    "    \n",
    "Some values stick out: 96, 98.  What should we do about them?\n",
    "    \n",
    "Data type is \"Object\" which usually means it's represented as a string.  \n",
    "Should we convert them to numbers?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From inspection and reading documentation we see some values that don't look right (Blanks, 99, 9999)\n",
    "## Cleaning empty fields and useless values, encode all as 98\n",
    "df0.replace(r'^\\s*$', '98', regex=True, inplace = True)\n",
    "df0.replace('^9[0-9]+', '98', regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the target vairable\n",
    "There are three pontential targets but we will use YPSUP07\n",
    "\n",
    "PSUP07  B  Ran away from home in last year                               \n",
    "\n",
    "          Value    Label\n",
    "\n",
    "              1    Never\n",
    "              2    A few times\n",
    "              3    Lots of times\n",
    "             96 M  More than 1 tick\n",
    "             98 M  Missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the target variaqble\n",
    "print(df0['YPSUP07'].value_counts())\n",
    "df0['YPSUP07'].value_counts().plot(\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove participants wiothout a valid answer to target vairable\n",
    "df0_new = df0[df0['YPSUP07'] != '98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to a bianary queastion to simplify the problem: \"Did run away AT ALL inm the last year\n",
    "df0_new['YPSUP07'].replace('1', '0', inplace=True)\n",
    "df0_new['YPSUP07'].replace('2', '1', inplace=True)\n",
    "df0_new['YPSUP07'].replace('3', '1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc = df0_new['YPSUP07'].value_counts()\n",
    "print(\"Binarised Target Variable:\")\n",
    "print(\"0 == Never ran away, 1 == Ran away at least once: \")\n",
    "print(df0_new['YPSUP07'].value_counts())\n",
    "print(\"Percent that ran away: \", round(vc[\"1\"]/len(df0_new),3)*100, \"%\")\n",
    "vc.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Other target variable:\n",
    "df0_new['YPSUP06'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "#YPSUP05 isn't in year 1\n",
    "#df0_new['YPSUP05'].value_counts().plot(kind=\"bar\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#metrics:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = df0_new['YPSUP07']\n",
    "features = df0_new.drop(['YPSUP05', 'YPSUP06','YPSUP07', \"DMMYID\"], 1, errors= \"ignore\") # 'YPSUP05','YPSUP06','YPSUP07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2, \n",
    "                                                        random_state=0, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_model_full_report(y_test, y_pred):\n",
    "    print('Accuracy: ', \"%.3f\" % (accuracy_score(y_test, y_pred)),'\\n')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                       columns=['PREDICTED 0', 'PREDICTED 1'],\n",
    "                       index=['ACTUAL 0', 'ACTUAL 1']),'\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['0','1']))\n",
    "    \n",
    "def print_model_report(y_test, y_pred):\n",
    "    print('\\t Accuracy: ', \"%.2f\" % (accuracy_score(y_test, y_pred)),\n",
    "          '\\t Recall:   ', \"%.2f\" % (recall_score(y_test, y_pred, pos_label='1')),\n",
    "          '\\t Precision:', \"%.2f\" % (precision_score(y_test, y_pred, pos_label='1')),\n",
    "          '\\t F1:', \"%.2f\" % (f1_score(y_test, y_pred, pos_label='1')),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                       columns=['Predicted No Risk (0)', 'Predicted Risk (1)'],\n",
    "                       index=['Actual No Risk (0)', 'Actual Risk (0)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to slides for a dsicussion on model evaluation and data inbalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the training data up by target response\n",
    "train_data = pd.concat([X_train, y_train], axis=1) \n",
    "train_stayhome = train_data[train_data.YPSUP07 == '0']\n",
    "train_runaways = train_data[train_data.YPSUP07 == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate the number of stay at homes we want to keep\n",
    "runaway_2_stayhome_ratio = 2\n",
    "num_stayhome = len(train_stayhome)\n",
    "num_runaways = len(train_runaways)\n",
    "num_undersample = int(ceil(runaway_2_stayhome_ratio * num_runaways))\n",
    "print(\"number train missing\", num_runaways)\n",
    "print(\"undersamples number train not missing\", num_undersample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# under sample stay at homes and recombine with ran aways\n",
    "train_stayhome_undersample = train_stayhome.sample(n=num_undersample, random_state=0)\n",
    "train_under = pd.concat([train_runaways, train_stayhome_undersample]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-split features and targets\n",
    "X_train_under = train_under.drop(['YPSUP07'], 1)\n",
    "y_train_under = train_under['YPSUP07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_under.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.value_counts().plot(\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train Model with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train_under, y_train_under)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to slides for discussion on Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_mdl= RandomForestClassifier(random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_mdl.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_mdl.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi = pd.Series(rf_mdl.feature_importances_)\n",
    "fi.index = X_train_under.columns\n",
    "fi.sort_values(inplace=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi[:10].plot.bar(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi[:20].plot.bar(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [0] # Fill this in with the values you want to test\n",
    "precision = {}\n",
    "recall = {}\n",
    "for p in params:\n",
    "    # train and test a model and add the: precision and recall to the respective ditionaries\n",
    "    precision[p] = 0 #fill this in (hint: use the function recall_score() and shift-tab to see what parameters it takes)\n",
    "    recall[p] = 0 #fill this in  (hint: use the function precision_score() and shift-tab to see what parameters it takes)\n",
    "    \n",
    "    \n",
    "pd.DataFrame({\"precision\":precision, \"recall\":recall}).plot()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
